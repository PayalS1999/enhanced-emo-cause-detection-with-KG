{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:21:41.240631Z",
     "start_time": "2025-04-03T07:21:14.209837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import json"
   ],
   "id": "24b17bca7fc83d01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:27:00.714584Z",
     "start_time": "2025-04-03T07:27:00.705822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ],
   "id": "db4b72f9bb124d27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/payalsaha/python311/bin/python3.11\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:24:19.471768Z",
     "start_time": "2025-04-03T07:24:19.434195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for conversation-level emotion causal detection.\n",
    "\n",
    "    Each sample is a full conversation and includes:\n",
    "      - conv_id: Conversation ID.\n",
    "      - utterances: Tensor of token IDs for all utterances (shape: [N, seq_len]).\n",
    "      - attention_masks: Tensor of attention masks (shape: [N, seq_len]).\n",
    "      - Ac: An (N, N) lower-triangular adjacency matrix (with self-loops).\n",
    "      - labels: A dictionary mapping candidate pairs (i, j) with j < i to binary labels.\n",
    "                The label is 1 if the candidate utterance (turn number) is in the target’s\n",
    "                \"expanded emotion cause evidence\"; otherwise 0.\n",
    "    \"\"\"\n",
    "    def __init__(self, json_file, tokenizer, max_length=64):\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "        # Get conversation IDs as a list for indexing.\n",
    "        self.conv_ids = list(self.data.keys())\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conv_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        conv_id = self.conv_ids[idx]\n",
    "        conv_instances = self.data[conv_id]\n",
    "        # Assume each conversation ID has at least one conversation instance;\n",
    "        # here, we take the first instance.\n",
    "        conv = conv_instances[0]\n",
    "        # Sort turns by \"turn\" field.\n",
    "        conv = sorted(conv, key=lambda x: x[\"turn\"])\n",
    "\n",
    "        utterances_list = []\n",
    "        attention_masks_list = []\n",
    "        for turn in conv:\n",
    "            encoded = self.tokenizer(\n",
    "                turn[\"utterance\"],\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True\n",
    "            )\n",
    "            utterances_list.append(encoded[\"input_ids\"].squeeze(0))\n",
    "            attention_masks_list.append(encoded[\"attention_mask\"].squeeze(0))\n",
    "        utterances = torch.stack(utterances_list, dim=0)          # (N, seq_len)\n",
    "        attention_masks = torch.stack(attention_masks_list, dim=0)  # (N, seq_len)\n",
    "\n",
    "        N = len(conv)\n",
    "        # Build Ac: Lower triangular matrix with self-loops.\n",
    "        Ac = torch.zeros((N, N), dtype=torch.long)\n",
    "        for i in range(N):\n",
    "            for j in range(i):\n",
    "                Ac[i, j] = 1\n",
    "            Ac[i, i] = 1\n",
    "\n",
    "        # Build labels dictionary.\n",
    "        labels = {}\n",
    "        for i in range(N):\n",
    "            target = conv[i]\n",
    "            # Proceed only if \"expanded emotion cause evidence\" exists and is a list.\n",
    "            if \"expanded emotion cause evidence\" in target and isinstance(target[\"expanded emotion cause evidence\"], list):\n",
    "                # Collect evidence turns that are integers.\n",
    "                evidence = [e for e in target[\"expanded emotion cause evidence\"] if isinstance(e, int)]\n",
    "                # For every candidate (j) preceding target (i)\n",
    "                for j in range(i):\n",
    "                    candidate = conv[j]\n",
    "                    candidate_turn = candidate[\"turn\"]\n",
    "                    label = 1 if candidate_turn in evidence else 0\n",
    "                    labels[(i, j)] = torch.tensor(label, dtype=torch.long)\n",
    "        sample = {\n",
    "            \"conv_id\": conv_id,\n",
    "            \"utterances\": utterances,           # (N, seq_len)\n",
    "            \"attention_masks\": attention_masks, # (N, seq_len)\n",
    "            \"Ac\": Ac,                           # (N, N)\n",
    "            \"labels\": labels                    # dict {(i, j): tensor(0 or 1)}\n",
    "        }\n",
    "        return sample"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:21:48.315585Z",
     "start_time": "2025-04-03T07:21:48.263514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------\n",
    "# Utterance Encoder\n",
    "# --------------------------\n",
    "class UtteranceEncoder(nn.Module):\n",
    "    def __init__(self, roberta_model_name='roberta-base', output_dim=300):\n",
    "        super(UtteranceEncoder, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(roberta_model_name)\n",
    "        self.linear = nn.Linear(self.roberta.config.hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        pooled, _ = torch.max(hidden_states, dim=1)\n",
    "        utterance_rep = self.linear(pooled)\n",
    "        return utterance_rep\n",
    "\n",
    "# --------------------------\n",
    "# DAGLayer (Graph-Based Aggregator)\n",
    "# --------------------------\n",
    "class DAGLayer(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(DAGLayer, self).__init__()\n",
    "        self.d = d\n",
    "        self.attn_linear = nn.Linear(2 * d, 1)\n",
    "        self.gru = nn.GRUCell(d, d)\n",
    "\n",
    "    def forward(self, h, Ac):\n",
    "        N = h.size(0)\n",
    "        device = h.device\n",
    "        updated_h = h.clone()\n",
    "        for i in range(N):\n",
    "            neighbor_msgs = []\n",
    "            for j in range(i):\n",
    "                if Ac[i, j] == 1:\n",
    "                    concat_vec = torch.cat([h[i], h[j]], dim=-1)\n",
    "                    attn_score = self.attn_linear(concat_vec)\n",
    "                    neighbor_msgs.append((j, attn_score))\n",
    "            if len(neighbor_msgs) > 0:\n",
    "                if len(neighbor_msgs) == 1:\n",
    "                    scores = neighbor_msgs[0][1].unsqueeze(0)\n",
    "                else:\n",
    "                    scores = torch.stack([score for (_, score) in neighbor_msgs]).squeeze(-1)\n",
    "                attn_weights = F.softmax(scores, dim=0)\n",
    "                agg = torch.zeros(self.d, device=device)\n",
    "                for idx, (j, _) in enumerate(neighbor_msgs):\n",
    "                    agg += attn_weights[idx] * h[j]\n",
    "                updated_h[i] = self.gru(agg, h[i])\n",
    "            else:\n",
    "                updated_h[i] = h[i]\n",
    "        return updated_h\n",
    "\n",
    "# --------------------------\n",
    "# Graph-Based Model (Without External Knowledge)\n",
    "# --------------------------\n",
    "class GraphModel(nn.Module):\n",
    "    def __init__(self, d=300, num_layers=2, roberta_model_name='roberta-base'):\n",
    "        super(GraphModel, self).__init__()\n",
    "        self.d = d\n",
    "        self.utterance_encoder = UtteranceEncoder(roberta_model_name, d)\n",
    "        self.num_layers = num_layers\n",
    "        self.dag_layers = nn.ModuleList([DAGLayer(d) for _ in range(num_layers)])\n",
    "        # Remove the final Sigmoid so that the model outputs logits.\n",
    "        self.cause_predictor = nn.Sequential(\n",
    "            nn.Linear(2 * d, 600),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(600, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, utterance_ids, attention_masks, Ac):\n",
    "        h = self.utterance_encoder(utterance_ids, attention_masks)\n",
    "        for layer in self.dag_layers:\n",
    "            h = layer(h, Ac)\n",
    "        N = h.size(0)\n",
    "        scores = {}\n",
    "        for i in range(N):\n",
    "            for j in range(i):\n",
    "                pair_rep = torch.cat([h[i], h[j]], dim=-1)\n",
    "                # Outputs logits\n",
    "                score = self.cause_predictor(pair_rep)\n",
    "                scores[(i, j)] = score\n",
    "        return scores"
   ],
   "id": "ad55a1449bcbf0cd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:22:01.201679Z",
     "start_time": "2025-04-03T07:22:01.175243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------\n",
    "# Training Loop with Weighted Loss\n",
    "# --------------------------\n",
    "def train_model_graph(model, dataloader, optimizer, num_epochs=2, device=\"cuda\"):\n",
    "    model.train()\n",
    "    # Set positive weight based on your dataset distribution (e.g., 4.13)\n",
    "    pos_weight = torch.tensor(4.13).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            utterances = batch[\"utterances\"].squeeze(0).to(device)\n",
    "            attention_masks = batch[\"attention_masks\"].squeeze(0).to(device)\n",
    "            Ac = batch[\"Ac\"].squeeze(0).to(device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scores = model(utterances, attention_masks, Ac)\n",
    "            loss = 0.0\n",
    "            count = 0\n",
    "            for key, score in scores.items():\n",
    "                label = labels.get(key, torch.tensor(0, dtype=torch.long)).to(device).float()\n",
    "                # Ensure both score and label are 1D tensors\n",
    "                loss += criterion(score.view(-1), label.view(-1))\n",
    "                count += 1\n",
    "            if count > 0:\n",
    "                loss = loss / count\n",
    "            else:\n",
    "                loss = torch.tensor(0.0, device=device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
   ],
   "id": "2473c984954e43d6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T07:41:01.935205Z",
     "start_time": "2025-04-03T07:41:01.903411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_model_graph(model, dataloader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    conversation_em_scores = []  # To record conversation-level exact match scores\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Process each conversation (batch_size assumed to be 1)\n",
    "            utterances = batch[\"utterances\"].squeeze(0).to(device)         # (N, seq_len)\n",
    "            attention_masks = batch[\"attention_masks\"].squeeze(0).to(device)  # (N, seq_len)\n",
    "            Ac = batch[\"Ac\"].squeeze(0).to(device)                            # (N, N)\n",
    "            labels = batch[\"labels\"]  # dict mapping candidate pair keys to tensor(0) or tensor(1)\n",
    "\n",
    "            # Get candidate pair scores from the model\n",
    "            scores = model(utterances, attention_masks, Ac)\n",
    "\n",
    "            convo_preds = {}\n",
    "            convo_gold = {}\n",
    "            for key, score in scores.items():\n",
    "                # Apply sigmoid to convert logits to probability\n",
    "                prob = torch.sigmoid(score)\n",
    "                pred = 1 if prob.item() >= 0.5 else 0\n",
    "                convo_preds[key] = pred\n",
    "                # If a key is missing, default label is 0\n",
    "                gold = labels.get(key, torch.tensor(0, dtype=torch.long)).item()\n",
    "                convo_gold[key] = gold\n",
    "\n",
    "                # Add to overall lists\n",
    "                all_preds.append(pred)\n",
    "                all_labels.append(gold)\n",
    "\n",
    "            # Compute conversation-level Exact Match:\n",
    "            # If all candidate pairs in this conversation are predicted correctly, count as EM=1; else 0.\n",
    "            if len(convo_gold) > 0 and all(convo_preds.get(k, 0) == v for k, v in convo_gold.items()):\n",
    "                conversation_em_scores.append(1)\n",
    "            else:\n",
    "                conversation_em_scores.append(0)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "    exact_match = sum(conversation_em_scores) / len(conversation_em_scores) if conversation_em_scores else 0.0\n",
    "\n",
    "    print(\"Evaluation Accuracy:\", accuracy)\n",
    "    print(\"Evaluation Macro F1:\", macro_f1)\n",
    "    print(\"Conversation-Level Exact Match (EM):\", exact_match)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    return accuracy, macro_f1, exact_match, report"
   ],
   "id": "773290d3624c7683",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T08:14:53.254008Z",
     "start_time": "2025-04-03T07:46:21.717402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    dataset = ConversationDataset(\"original_annotation/dailydialog_train.json\", tokenizer, max_length=64)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    model = GraphModel(d=300, num_layers=2, roberta_model_name=\"roberta-base\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "    begin  = time.time()\n",
    "    # Train the model with weighted loss\n",
    "    train_model_graph(model, dataloader, optimizer, num_epochs=10, device=device)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Elapsed time for training: {end-begin}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model_graph(model, dataloader, device=device)"
   ],
   "id": "5ab77743f57cd78c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 834/834 [02:27<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 834/834 [02:45<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 834/834 [02:45<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 834/834 [02:46<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 834/834 [02:46<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.9342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 834/834 [02:45<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 834/834 [02:46<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 834/834 [02:47<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 834/834 [02:46<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 834/834 [02:46<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.9284\n",
      "Elapsed time for training: 1643.7697632312775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 834/834 [01:05<00:00, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.8287833895008255\n",
      "Evaluation Macro F1: 0.6319499152860791\n",
      "Conversation-Level Exact Match (EM): 0.002398081534772182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9376    0.8674    0.9011     39761\n",
      "           1     0.2901    0.4841    0.3628      4452\n",
      "\n",
      "    accuracy                         0.8288     44213\n",
      "   macro avg     0.6138    0.6757    0.6319     44213\n",
      "weighted avg     0.8724    0.8288    0.8469     44213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T08:15:07.696266Z",
     "start_time": "2025-04-03T08:15:00.591259Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"kec_model-graph.pt\")",
   "id": "3671face80c4243b",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "dataset = ConversationDataset(\"original_annotation/dailydialog_train.json\", tokenizer, max_length=64)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "evaluate_model_graph(model, dataloader, device)\"\"\""
   ],
   "id": "8c62f69c4d65abb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T08:15:13.039793Z",
     "start_time": "2025-04-03T08:15:07.720443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "dataset = ConversationDataset(\"original_annotation/dailydialog_valid.json\", tokenizer, max_length=64)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "evaluate_model_graph(model, dataloader, device)"
   ],
   "id": "315c93a0e7f9f55e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 47/47 [00:04<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.8393724318266716\n",
      "Evaluation Macro F1: 0.624520175463776\n",
      "Conversation-Level Exact Match (EM): 0.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9596    0.8627    0.9085      2476\n",
      "           1     0.2461    0.5522    0.3405       201\n",
      "\n",
      "    accuracy                         0.8394      2677\n",
      "   macro avg     0.6028    0.7075    0.6245      2677\n",
      "weighted avg     0.9060    0.8394    0.8659      2677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8393724318266716,\n",
       " 0.624520175463776,\n",
       " 0.0,\n",
       " '              precision    recall  f1-score   support\\n\\n           0     0.9596    0.8627    0.9085      2476\\n           1     0.2461    0.5522    0.3405       201\\n\\n    accuracy                         0.8394      2677\\n   macro avg     0.6028    0.7075    0.6245      2677\\nweighted avg     0.9060    0.8394    0.8659      2677\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T08:15:32.556453Z",
     "start_time": "2025-04-03T08:15:13.064008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "dataset = ConversationDataset(\"original_annotation/dailydialog_test.json\", tokenizer, max_length=64)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "evaluate_model_graph(model, dataloader, device)"
   ],
   "id": "b6754a5967e36b95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 225/225 [00:18<00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.8344267183539585\n",
      "Evaluation Macro F1: 0.6143751198828616\n",
      "Conversation-Level Exact Match (EM): 0.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9493    0.8659    0.9057     12315\n",
      "           1     0.2429    0.4823    0.3231      1099\n",
      "\n",
      "    accuracy                         0.8344     13414\n",
      "   macro avg     0.5961    0.6741    0.6144     13414\n",
      "weighted avg     0.8915    0.8344    0.8579     13414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8344267183539585,\n",
       " 0.6143751198828616,\n",
       " 0.0,\n",
       " '              precision    recall  f1-score   support\\n\\n           0     0.9493    0.8659    0.9057     12315\\n           1     0.2429    0.4823    0.3231      1099\\n\\n    accuracy                         0.8344     13414\\n   macro avg     0.5961    0.6741    0.6144     13414\\nweighted avg     0.8915    0.8344    0.8579     13414\\n')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
